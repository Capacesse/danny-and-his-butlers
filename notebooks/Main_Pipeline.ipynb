{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYjsfuFENr6g"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TOr15U0DlWA9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynpSNE0EOFT2"
      },
      "source": [
        "Authenticate w/ Hugging Face Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--qFJ9gCNv-8",
        "outputId": "e933bff0-019e-4cec-e41e-8079575d58cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HuggingFace token successfully found.\n"
          ]
        }
      ],
      "source": [
        "huggingface_token = userdata.get('TikTokTechJam2025')\n",
        "\n",
        "if huggingface_token:\n",
        "  print(\"HuggingFace token successfully found.\")\n",
        "else:\n",
        "  print(\"HuggingFace token not found. Please add it to the Secrets manager using the name 'TikTokTechJam2025'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mount Google Drive & add project to path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/MyDrive/TikTok_Tech_Jam' \n",
        "sys.path.append(f'{project_path}/src')\n",
        "\n",
        "print(\"Drive mounted and project path added.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import .py files in src folder\n",
        "from data_preprocessing import preprocess_data\n",
        "from image_analysis import generate_image_descriptions_from_folder\n",
        "from feature_engineering import get_unified_data\n",
        "# from model_training import train_and_evaluate_model\n",
        "# from policy_enforcement import classify_new_review\n",
        "\n",
        "print(\"Modules imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define file paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store/Organise all file paths in one place\n",
        "RAW_DATA_PATH = f'{project_path}/data/reviews.csv'\n",
        "PROCESSED_DATA_PATH = f'{project_path}/data/processed_reviews.csv'\n",
        "IMAGE_FOLDER_PATH = f'{project_path}/data/image_dataset/'\n",
        "\n",
        "MODEL_FEATURES_PATH = f'{project_path}/data/model_features.csv'\n",
        "LOOKUP_TABLE_PATH = f'{project_path}/data/reviews_lookup.csv'\n",
        "MODEL_SAVE_PATH = f'{project_path}/models/student_model.pkl'\n",
        "\n",
        "print(\"File paths defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Step 1: Data Preprocessing ===\n",
        "print(\"--- Running Data Preprocessing ---\")\n",
        "# Call the function from src/data_preprocessing.py\n",
        "preprocess_data(\n",
        "    input_file=RAW_DATA_PATH,\n",
        "    output_file=PROCESSED_DATA_PATH,\n",
        "    image_folder_path=IMAGE_FOLDER_PATH\n",
        ")\n",
        "print(\"--- Data Preprocessing Complete ---\\n\")\n",
        "\n",
        "# === Step 2: Feature Engineering ===\n",
        "print(\"--- Running Feature Engineering ---\")\n",
        "# Call the function from src/feature_engineering.py\n",
        "get_unified_data(PROCESSED_DATA_PATH)\n",
        "print(\"--- Feature Engineering Complete ---\")\n",
        "\n",
        "# === Step 3: Model Training ===\n",
        "print(\"--- Running Model Training ---\")\n",
        "## (The next steps for model training will go in subsequent cells)\n",
        "\n",
        "# === Step 4: Policy Enforcement ===\n",
        "print(\"--- Running Policy Enforcement ---\")\n",
        "## (The next steps for policy enforcement will go in subsequent cells)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
